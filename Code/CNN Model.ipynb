{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7b37ebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crepe\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57f521d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropadding(array, SamplePerWindow):\n",
    "    if(array.size%SamplePerWindow != 0):\n",
    "        left = array.size%SamplePerWindow\n",
    "        add = np.zeros(SamplePerWindow - left)\n",
    "        new_arr = np.append(array, add)\n",
    "        return new_arr\n",
    "    else:\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a0229ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training datasize: 166753.0  -frames\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "X = []\n",
    "SamplePerWindow = 480 ## sample rate 48000/s 0.01sec/window\n",
    "for dirname, _, filenames in os.walk('new_dataset/'):    ## Read data\n",
    "    for filename in filenames:\n",
    "        sr, audio = wavfile.read(os.path.join(dirname,filename))\n",
    "        new_audio = zeropadding(audio, SamplePerWindow)\n",
    "        #print(os.path.join(dirname, filename), 'audio size: ', new_audio.size)\n",
    "        audio_max = np.amax(new_audio)  #normalize data\n",
    "        new_audio = new_audio / audio_max\n",
    "        X = np.append(X, new_audio);\n",
    "        \n",
    "print('Total Training datasize:',X.size/480,' -frames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "54fa7dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0 1951.0\n",
      "Total labels: (166753,)\n",
      "Total frames: (166753, 480, 1)\n"
     ]
    }
   ],
   "source": [
    "Y=[]\n",
    "\n",
    "for dirname, _, filenames in os.walk('txtfile/'):  ##Read the Y labels for the data\n",
    "    for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "        data= pd.read_csv(os.path.join(dirname, filename))\n",
    "        temp = np.array(data.frequency)\n",
    "        #print(os.path.join(dirname, filename), 'Frames:', temp.size)\n",
    "        Y = np.append(Y,temp)\n",
    "\n",
    "minY = np.amin(Y)\n",
    "for i in range(Y.size):\n",
    "    Y[i] = Y[i] - minY\n",
    "maxY = np.amax(Y)\n",
    "print(minY, maxY)\n",
    "X = np.reshape(X, (Y.size-1,480,1))\n",
    "Y = Y[0:Y.size-1]\n",
    "\n",
    "print('Total labels:', Y.shape)\n",
    "print('Total frames:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b179a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (166753, 480, 1)\n",
      "Y label shape: (166753,)\n"
     ]
    }
   ],
   "source": [
    "print('X data shape:',X.shape)\n",
    "print('Y label shape:', Y.shape)\n",
    "# for i in range(Y.size):\n",
    "#     if Y[i] > 400:\n",
    "#         Y[i] = 400\n",
    "        \n",
    "X_new = X[40000:120000]\n",
    "Y_new = Y[40000:120000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a5d3345b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 480, 1) (64000,)\n",
      "(16000, 480, 1) (16000,)\n"
     ]
    }
   ],
   "source": [
    "#split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_new,Y_new,test_size=0.2)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "SamplePerFrame = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8b31c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 478, 128)          512       \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 239, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 237, 64)           24640     \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 118, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 7552)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1024)              7734272   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2048)              2099200   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1952)              3999648   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,858,272\n",
      "Trainable params: 13,858,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#CNN Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, MaxPooling1D, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(480,1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='sigmoid'))\n",
    "model.add(Dense(2048, activation='sigmoid'))\n",
    "model.add(Dense(1952, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "89874391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 147s 73ms/step - loss: 3.8585 - accuracy: 0.0785\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 142s 71ms/step - loss: 3.7826 - accuracy: 0.0895\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 145s 73ms/step - loss: 3.7069 - accuracy: 0.0988\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 158s 79ms/step - loss: 3.6242 - accuracy: 0.1080\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 160s 80ms/step - loss: 3.5412 - accuracy: 0.1210\n",
      "INFO:tensorflow:Assets written to: CNNModel\\assets\n"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.save('CNNModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbacc71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 4.1298 - accuracy: 0.0644\n"
     ]
    }
   ],
   "source": [
    "print('Testing data')\n",
    "val_loss, val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce7d9f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111718 111840\n",
      "(233, 480, 1)\n",
      "(233, 1952)\n",
      "(233,)\n",
      "pitch file prediction created\n"
     ]
    }
   ],
   "source": [
    "sr, audio = wavfile.read('test_dataset/test.wav')\n",
    "\n",
    "new_audio = []\n",
    "\n",
    "for i in range(audio.size):\n",
    "    if audio[i]>60 or audio[i]<-60:\n",
    "        new_audio = np.append(new_audio, audio[i])\n",
    "new_audio = np.array(new_audio)\n",
    "new_audio = zeropadding(new_audio, SamplePerWindow)\n",
    "\n",
    "print(audio.size, new_audio.size)\n",
    "dim = int(new_audio.size/480)\n",
    "\n",
    "test_audio = np.reshape(new_audio, (dim, 480, 1))\n",
    "print(test_audio.shape)\n",
    "test_output = model.predict(test_audio)\n",
    "print(test_output.shape)\n",
    "output = []\n",
    "\n",
    "for i in range(dim):\n",
    "    #print('max:', np.argmax(test_output[i][1:300]))\n",
    "    result = np.where(test_output[i][50:500] == np.amax(test_output[i][80:500]))   \n",
    "    result = result\n",
    "    #print(i, result)\n",
    "    output = np.append(output, result) \n",
    "    \n",
    "file1 = open(\"pitch_demo\\CNNModel1_test.csv\",\"w\")\n",
    "for i in range(dim):\n",
    "    file1.write(str(output[i]))\n",
    "    file1.write('\\n')\n",
    "file1.close()\n",
    "    \n",
    "print(output.shape)\n",
    "print('pitch file prediction created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d8ff8f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101393 101760\n",
      "(212, 480, 1)\n",
      "(212, 1952)\n",
      "(212,)\n"
     ]
    }
   ],
   "source": [
    "sr, audio = wavfile.read('test_dataset/test1.wav')\n",
    "\n",
    "new_audio = []\n",
    "\n",
    "for i in range(audio.size):\n",
    "    if audio[i]>60 or audio[i]<-60:\n",
    "        new_audio = np.append(new_audio, audio[i])\n",
    "new_audio = np.array(new_audio)\n",
    "new_audio = zeropadding(new_audio, SamplePerWindow)\n",
    "\n",
    "print(audio.size, new_audio.size)\n",
    "dim = int(new_audio.size/480)\n",
    "\n",
    "test_audio = np.reshape(new_audio, (dim, 480, 1))\n",
    "print(test_audio.shape)\n",
    "test_output = model.predict(test_audio)\n",
    "print(test_output.shape)\n",
    "output = []\n",
    "\n",
    "for i in range(dim):\n",
    "    #print('max:', np.argmax(test_output[i][1:300]))\n",
    "    result = np.where(test_output[i][50:300] == np.amax(test_output[i][60:300]))   \n",
    "    result = result\n",
    "    #print(i, result)\n",
    "    output = np.append(output, result) \n",
    "    \n",
    "file1 = open(\"pitch_demo\\CNNModel1_test1.csv\",\"w\")\n",
    "for i in range(dim):\n",
    "    file1.write(str(output[i]))\n",
    "    file1.write('\\n')\n",
    "file1.close()\n",
    "    \n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f1a2058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98e29ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 478, 128)          512       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 239, 128)         0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 237, 128)          49280     \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 118, 128)         0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 116, 256)          98560     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 58, 256)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 14848)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              15205376  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2048)              2099200   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1952)              3999648   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,452,576\n",
      "Trainable params: 21,452,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Another larger model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu', input_shape=(480,1)))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=128, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Conv1D(filters=256, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dense(2048, activation='relu'))\n",
    "model.add(Dense(1952, activation='softmax'))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d1fc1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 234s 117ms/step - loss: 5.1438 - accuracy: 0.0152\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 217s 108ms/step - loss: 4.2705 - accuracy: 0.0469\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 242s 121ms/step - loss: 4.0204 - accuracy: 0.0664\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 221s 111ms/step - loss: 3.8784 - accuracy: 0.0786\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 237s 118ms/step - loss: 3.7450 - accuracy: 0.0925\n",
      "INFO:tensorflow:Assets written to: CNN1Model\\assets\n"
     ]
    }
   ],
   "source": [
    "#Model Training\n",
    "batch_size = 32\n",
    "steps_per_epoch = int( np.ceil(x_train.shape[0] / batch_size) )\n",
    "model.fit(x_train, y_train, epochs=5, steps_per_epoch = steps_per_epoch)\n",
    "model.save('CNN1Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0dfa0a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data\n",
      "500/500 [==============================] - 5s 11ms/step - loss: 4.0450 - accuracy: 0.0625\n"
     ]
    }
   ],
   "source": [
    "print('Testing data')\n",
    "val_loss, val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6011b9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111718 111840\n",
      "(233, 480, 1)\n",
      "(233, 1952)\n",
      "(233,)\n"
     ]
    }
   ],
   "source": [
    "sr, audio = wavfile.read('test_dataset/test.wav')\n",
    "\n",
    "new_audio = []\n",
    "\n",
    "for i in range(audio.size):\n",
    "    if audio[i]>60 or audio[i]<-60:\n",
    "        new_audio = np.append(new_audio, audio[i])\n",
    "new_audio = np.array(new_audio)\n",
    "new_audio = zeropadding(new_audio, SamplePerWindow)\n",
    "max_new_audio = np.amax(new_audio)\n",
    "new_audio = new_audio/max_new_audio\n",
    "\n",
    "print(audio.size, new_audio.size)\n",
    "dim = int(new_audio.size/480)\n",
    "\n",
    "test_audio = np.reshape(new_audio, (dim, 480, 1))\n",
    "print(test_audio.shape)\n",
    "test_output = model.predict(test_audio)\n",
    "print(test_output.shape)\n",
    "output = []\n",
    "\n",
    "for i in range(dim):\n",
    "    #print('max:', np.argmax(test_output[i][1:300]))\n",
    "    result = np.where(test_output[i][50:500] == np.amax(test_output[i][80:500]))   \n",
    "    result = result\n",
    "    #print(i, result)\n",
    "    output = np.append(output, result) \n",
    "    \n",
    "file1 = open(\"pitch_demo\\CNNModel2_test.csv\",\"w\")\n",
    "for i in range(dim):\n",
    "    file1.write(str(output[i]))\n",
    "    file1.write('\\n')\n",
    "file1.close()\n",
    "    \n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b6a029e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101393 101760\n",
      "(212, 480, 1)\n",
      "(212, 1952)\n",
      "(212,)\n"
     ]
    }
   ],
   "source": [
    "sr, audio = wavfile.read('test_dataset/test1.wav')\n",
    "new_audio = []\n",
    "\n",
    "for i in range(audio.size):\n",
    "    if audio[i]>60 or audio[i]<-60:\n",
    "        new_audio = np.append(new_audio, audio[i])\n",
    "new_audio = np.array(new_audio)\n",
    "new_audio = zeropadding(new_audio, SamplePerWindow)\n",
    "max_new_audio = np.amax(new_audio)\n",
    "new_audio = new_audio/max_new_audio\n",
    "\n",
    "print(audio.size, new_audio.size)\n",
    "dim = int(new_audio.size/480)\n",
    "\n",
    "test_audio = np.reshape(new_audio, (dim, 480, 1))\n",
    "print(test_audio.shape)\n",
    "test_output = model.predict(test_audio)\n",
    "print(test_output.shape)\n",
    "output = []\n",
    "\n",
    "for i in range(dim):\n",
    "    #print('max:', np.argmax(test_output[i][1:300]))\n",
    "    result = np.where(test_output[i][50:500] == np.amax(test_output[i][50:500]))   \n",
    "    result = result\n",
    "    #print(i, result)\n",
    "    output = np.append(output, result) \n",
    "    \n",
    "file1 = open(\"pitch_demo\\CNNModel2_test1.csv\",\"w\")\n",
    "for i in range(dim):\n",
    "    file1.write(str(output[i]))\n",
    "    file1.write('\\n')\n",
    "file1.close()\n",
    "    \n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5783de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
