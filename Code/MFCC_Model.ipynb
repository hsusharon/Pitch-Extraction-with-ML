{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314acbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import crepe\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "285459ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeropadding(array, SamplePerWindow):\n",
    "    if(array.size%SamplePerWindow != 0):\n",
    "        left = array.size%SamplePerWindow\n",
    "        add = np.zeros(SamplePerWindow - left)\n",
    "        new_arr = np.append(array, add)\n",
    "        return new_arr\n",
    "    else:\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3afdd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training datasize: (166753, 26)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import python_speech_features\n",
    "\n",
    "X = []\n",
    "SamplePerWindow = 480 ## sample rate 48000/s 0.01sec/window\n",
    "for dirname, _, filenames in os.walk('new_dataset/'):    ## Read data\n",
    "    for filename in filenames:\n",
    "        sr, audio = wavfile.read(os.path.join(dirname,filename))\n",
    "        audio = zeropadding(audio, SamplePerWindow)\n",
    "        ##Feature Extraction\n",
    "        mfcc_speech = python_speech_features.mfcc(signal=audio, samplerate=sr, winlen=0.01, winstep=0.005,nfft=1024)\n",
    "        newdata = []\n",
    "        i=0\n",
    "        while i<mfcc_speech.shape[0]:\n",
    "            row = []\n",
    "            if i == mfcc_speech.shape[0]-1:\n",
    "                row.append(mfcc_speech[i])\n",
    "                row = np.append(row, mfcc_speech[i])\n",
    "            else:\n",
    "                sub = mfcc_speech[i] - mfcc_speech[i+1]\n",
    "                row.append(mfcc_speech[i])\n",
    "                row = np.append(row, sub)\n",
    "            newdata.append(row)\n",
    "            i = i+2\n",
    "#             newdata = np.array(newdata)\n",
    "            \n",
    "        X = np.append(X, newdata)\n",
    "#         print(os.path.join(dirname, filename), 'MFCC data shape: ', newdata.shape) \n",
    "        \n",
    "        \n",
    "X = np.array(X)\n",
    "length = int(X.size/26)\n",
    "X = np.reshape(X, (length, 26))\n",
    "print('Total Training datasize:',X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b468f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label file Y loaded\n",
      "31.0 1951.0\n",
      "Total labels: (166753,)\n",
      "Total frames: (166753, 26)\n"
     ]
    }
   ],
   "source": [
    "Y=[]\n",
    "\n",
    "for dirname, _, filenames in os.walk('txtfile/'):  ##Read the Y labels for the data\n",
    "    for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "        data= pd.read_csv(os.path.join(dirname, filename))\n",
    "        temp = np.array(data.frequency)\n",
    "#         print(os.path.join(dirname, filename), 'Frames:', temp.size)\n",
    "        Y = np.append(Y,temp)\n",
    "print('Label file Y loaded')\n",
    "\n",
    "minY = np.amin(Y)\n",
    "for i in range(Y.size):\n",
    "    Y[i] = Y[i] - minY\n",
    "maxY = np.amax(Y)\n",
    "print(minY, maxY)\n",
    "Y = Y[0:Y.size-1]\n",
    "\n",
    "print('Total labels:', Y.shape)\n",
    "print('Total frames:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d0349b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X data shape: (166753, 26)\n",
      "Y label shape: (166753,)\n"
     ]
    }
   ],
   "source": [
    "print('X data shape:',X.shape)\n",
    "print('Y label shape:', Y.shape)\n",
    "# for i in range(Y.size):\n",
    "#     if Y[i] > 400:\n",
    "#         Y[i] = 400\n",
    "        \n",
    "X_new = X[40000:160000]\n",
    "Y_new = Y[40000:160000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26be42da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 26) (96000,)\n",
      "(24000, 26) (24000,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(X_new,Y_new,test_size=0.2)\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "SamplePerFrame = 480"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "032cc5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (1, 26)                   0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (1, 512)                  13824     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (1, 1024)                 525312    \n",
      "                                                                 \n",
      " dense_7 (Dense)             (1, 2048)                 2099200   \n",
      "                                                                 \n",
      " dense_8 (Dense)             (1, 2048)                 4196352   \n",
      "                                                                 \n",
      " dense_9 (Dense)             (1, 1955)                 4005795   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,840,483\n",
      "Trainable params: 10,840,483\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu)) \n",
    "model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu)) \n",
    "model.add(tf.keras.layers.Dense(2048, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(2048, activation=tf.nn.relu)) \n",
    "model.add(tf.keras.layers.Dense(1955, activation=tf.nn.softmax)) \n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.build((1,26))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701cd447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3000/3000 [==============================] - 152s 50ms/step - loss: 5.0161 - accuracy: 0.0183\n",
      "Epoch 2/10\n",
      "3000/3000 [==============================] - 138s 46ms/step - loss: 4.8341 - accuracy: 0.0223\n",
      "Epoch 3/10\n",
      "3000/3000 [==============================] - 133s 44ms/step - loss: 4.7540 - accuracy: 0.0259\n",
      "Epoch 4/10\n",
      "3000/3000 [==============================] - 148s 49ms/step - loss: 4.6913 - accuracy: 0.0304\n",
      "Epoch 5/10\n",
      "3000/3000 [==============================] - 155s 52ms/step - loss: 4.6343 - accuracy: 0.0324\n",
      "Epoch 6/10\n",
      "3000/3000 [==============================] - 157s 52ms/step - loss: 4.5840 - accuracy: 0.0372\n",
      "Epoch 7/10\n",
      "3000/3000 [==============================] - 152s 51ms/step - loss: 4.5362 - accuracy: 0.0395\n",
      "Epoch 8/10\n",
      "3000/3000 [==============================] - 147s 49ms/step - loss: 4.4879 - accuracy: 0.0440\n",
      "Epoch 9/10\n",
      "3000/3000 [==============================] - 151s 50ms/step - loss: 4.4449 - accuracy: 0.0481\n",
      "Epoch 10/10\n",
      "3000/3000 [==============================] - 149s 50ms/step - loss: 4.3962 - accuracy: 0.0540\n",
      "INFO:tensorflow:Assets written to: MyModel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10) #15\n",
    "\n",
    "model.save('MyModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b3c05a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data\n",
      "750/750 [==============================] - 7s 9ms/step - loss: 4.8973 - accuracy: 0.0322\n"
     ]
    }
   ],
   "source": [
    "print('Testing data')\n",
    "val_loss, val_acc = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e399c205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111718 (233, 26)\n",
      "predict output: (233, 1955)\n",
      "(233,)\n"
     ]
    }
   ],
   "source": [
    "sr, audio = wavfile.read('test_dataset/test.wav')\n",
    "\n",
    "new_audio = zeropadding(audio, SamplePerWindow)\n",
    "\n",
    "mfcc_speech = python_speech_features.mfcc(signal=audio, samplerate=sr, winlen=0.01, winstep=0.005,nfft=1024)\n",
    "newdata = []\n",
    "i=0\n",
    "while i<mfcc_speech.shape[0]:\n",
    "    row = []\n",
    "    if i == mfcc_speech.shape[0]-1:\n",
    "        row.append(mfcc_speech[i])\n",
    "        row = np.append(row, mfcc_speech[i])\n",
    "    else:\n",
    "        sub = mfcc_speech[i] - mfcc_speech[i+1]\n",
    "        row.append(mfcc_speech[i])\n",
    "        row = np.append(row, sub)\n",
    "    newdata.append(row)\n",
    "    i = i+2\n",
    "\n",
    "new_audio = np.array(newdata)\n",
    "\n",
    "print(audio.size, new_audio.shape)\n",
    "dim = new_audio.shape[0]\n",
    "\n",
    "test_output = model.predict(new_audio)\n",
    "print('predict output:',test_output.shape)\n",
    "output = []\n",
    "\n",
    "\n",
    "for i in range(dim):\n",
    "    #print('max:', np.argmax(test_output[i][1:400]))\n",
    "    result = np.where(test_output[i][50:500] == np.amax(test_output[i][80:500]))   \n",
    "    result = result\n",
    "    #print(i, result)\n",
    "    output = np.append(output, result) \n",
    "    \n",
    "file1 = open(\"pitch_demo\\MFCC_MyModel_test.csv\",\"w\")\n",
    "for i in range(dim):\n",
    "    file1.write(str(output[i]))\n",
    "    file1.write('\\n')\n",
    "file1.close()\n",
    "    \n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a54b2aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101393 (211, 26)\n",
      "predict output: (211, 1955)\n",
      "(211,)\n"
     ]
    }
   ],
   "source": [
    "sr, audio = wavfile.read('test_dataset/test1.wav')\n",
    "\n",
    "new_audio = zeropadding(audio, SamplePerWindow)\n",
    "\n",
    "mfcc_speech = python_speech_features.mfcc(signal=audio, samplerate=sr, winlen=0.01, winstep=0.005,nfft=1024)\n",
    "newdata = []\n",
    "i=0\n",
    "while i<mfcc_speech.shape[0]:\n",
    "    row = []\n",
    "    if i == mfcc_speech.shape[0]-1:\n",
    "        row.append(mfcc_speech[i])\n",
    "        row = np.append(row, mfcc_speech[i])\n",
    "    else:\n",
    "        sub = mfcc_speech[i] - mfcc_speech[i+1]\n",
    "        row.append(mfcc_speech[i])\n",
    "        row = np.append(row, sub)\n",
    "    newdata.append(row)\n",
    "    i = i+2\n",
    "\n",
    "new_audio = np.array(newdata)\n",
    "\n",
    "print(audio.size, new_audio.shape)\n",
    "dim = new_audio.shape[0]\n",
    "\n",
    "test_output = model.predict(new_audio)\n",
    "print('predict output:',test_output.shape)\n",
    "output = []\n",
    "\n",
    "\n",
    "for i in range(dim):\n",
    "    #print('max:', np.argmax(test_output[i][1:400]))\n",
    "    result = np.where(test_output[i][50:500] == np.amax(test_output[i][80:500]))   \n",
    "    result = result\n",
    "    #print(i, result)\n",
    "    output = np.append(output, result) \n",
    "    \n",
    "file1 = open(\"pitch_demo\\MFCC_MyModel_test1.csv\",\"w\")\n",
    "for i in range(dim):\n",
    "    file1.write(str(output[i]))\n",
    "    file1.write('\\n')\n",
    "file1.close()\n",
    "    \n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99dd13b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
